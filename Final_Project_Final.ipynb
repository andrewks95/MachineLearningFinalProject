{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "nltk.download('punkt') # Pre-trained tokenizer to help tokenize sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd #  Initially thought I might need this due to all sorts of errors with large datasets. Manged to fix them\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processtext(x):\n",
    "    filtered_list = []\n",
    "    text_tokens = word_tokenize(str(x))\n",
    "    for w in text_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_list.append(w)\n",
    "    filtered_sentence = (\" \").join(filtered_list)\n",
    "    filtered_sentence = re.sub(r'[^\\w]', ' ', filtered_sentence)\n",
    "    filtered_sentence = re.sub(r\"\\d\", \"\", filtered_sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "with open(\"C:/Users/andre/Documents/tweets.csv\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                              tweet\n",
       "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1         0  is upset that he can't update his Facebook by ...\n",
       "2         0  @Kenichan I dived many times for the ball. Man...\n",
       "3         0    my whole body feels itchy and like its on fire \n",
       "4         0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/andre/Documents/tweets2.csv\", encoding = 'UTF-8',\n",
    "                names = [\"polarity\", \"tweet\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(processtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot http twitpic Awww bummer shoulda Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset update Facebook texting might result Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Kenichan dived many times ball Managed save re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass behaving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                              tweet\n",
       "0         0  switchfoot http twitpic Awww bummer shoulda Da...\n",
       "1         0  upset update Facebook texting might result Sch...\n",
       "2         0  Kenichan dived many times ball Managed save re...\n",
       "3         0                   whole body feels itchy like fire\n",
       "4         0                           nationwideclass behaving"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "        \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>switchfoot http twitpic Awww bummer shoulda Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset update Facebook texting might result Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Kenichan dived many times ball Managed save re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwideclass behaving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                              tweet\n",
       "0         0  switchfoot http twitpic Awww bummer shoulda Da...\n",
       "1         0  upset update Facebook texting might result Sch...\n",
       "2         0  Kenichan dived many times ball Managed save re...\n",
       "3         0                   whole body feels itchy like fire\n",
       "4         0                           nationwideclass behaving"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data Samples: 734003\n",
      "Test data Samples: 314573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['polarity']\n",
    "X = df['tweet']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)\n",
    "print('Train data Samples:', X_train.shape[0])\n",
    "print('Test data Samples:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "tk = Tokenizer(num_words=5000)\n",
    "vocab_size = len(tk.word_index) + 1\n",
    "\n",
    "tk.fit_on_texts(X_train)\n",
    "tk.fit_on_texts(X_test)\n",
    "\n",
    "# For Sequences\n",
    "X_train_seq = tk.texts_to_sequences(X_train)\n",
    "X_test_seq = tk.texts_to_sequences(X_test)\n",
    "\n",
    "#Padding to make equal length sentences\n",
    "X_train_padded = pad_sequences(X_train_seq, padding = \"post\")\n",
    "X_test_padded = pad_sequences(X_test_seq, padding = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': 1,\n",
       " 'work': 2,\n",
       " 'good': 3,\n",
       " 'today': 4,\n",
       " 'going': 5,\n",
       " 'quot': 6,\n",
       " 'back': 7,\n",
       " 'http': 8,\n",
       " 'really': 9,\n",
       " 'time': 10,\n",
       " 'know': 11,\n",
       " 'still': 12,\n",
       " 'want': 13,\n",
       " 'miss': 14,\n",
       " 'love': 15,\n",
       " 'home': 16,\n",
       " 'night': 17,\n",
       " 'think': 18,\n",
       " 'well': 19,\n",
       " 'last': 20,\n",
       " 'need': 21,\n",
       " 'much': 22,\n",
       " 'feel': 23,\n",
       " 'wish': 24,\n",
       " 'tomorrow': 25,\n",
       " 'sorry': 26,\n",
       " 'sleep': 27,\n",
       " 'morning': 28,\n",
       " 'hope': 29,\n",
       " 'could': 30,\n",
       " 'twitter': 31,\n",
       " 'would': 32,\n",
       " 'right': 33,\n",
       " 'hate': 34,\n",
       " 'just': 35,\n",
       " 'though': 36,\n",
       " 'thanks': 37,\n",
       " 'tonight': 38,\n",
       " 'getting': 39,\n",
       " 'great': 40,\n",
       " 'come': 41,\n",
       " 'make': 42,\n",
       " 'haha': 43,\n",
       " 'week': 44,\n",
       " 'school': 45,\n",
       " 'sick': 46,\n",
       " 'happy': 47,\n",
       " 'better': 48,\n",
       " 'even': 49,\n",
       " 'dont': 50,\n",
       " 'cant': 51,\n",
       " 'yeah': 52,\n",
       " 'people': 53,\n",
       " 'tired': 54,\n",
       " 'days': 55,\n",
       " 'never': 56,\n",
       " 'working': 57,\n",
       " 'weekend': 58,\n",
       " 'watching': 59,\n",
       " 'feeling': 60,\n",
       " 'next': 61,\n",
       " 'wait': 62,\n",
       " 'nice': 63,\n",
       " 'long': 64,\n",
       " 'soon': 65,\n",
       " 'take': 66,\n",
       " 'that': 67,\n",
       " 'little': 68,\n",
       " 'already': 69,\n",
       " 'find': 70,\n",
       " 'twitpic': 71,\n",
       " 'phone': 72,\n",
       " 'please': 73,\n",
       " 'life': 74,\n",
       " 'show': 75,\n",
       " 'another': 76,\n",
       " 'hours': 77,\n",
       " 'lost': 78,\n",
       " 'sucks': 79,\n",
       " 'damn': 80,\n",
       " 'first': 81,\n",
       " 'watch': 82,\n",
       " 'thing': 83,\n",
       " 'away': 84,\n",
       " 'something': 85,\n",
       " 'went': 86,\n",
       " 'done': 87,\n",
       " 'trying': 88,\n",
       " 'missed': 89,\n",
       " 'always': 90,\n",
       " 'left': 91,\n",
       " 'what': 92,\n",
       " 'rain': 93,\n",
       " 'friends': 94,\n",
       " 'everyone': 95,\n",
       " 'bored': 96,\n",
       " 'house': 97,\n",
       " 'early': 98,\n",
       " 'someone': 99,\n",
       " 'ready': 100,\n",
       " 'best': 101,\n",
       " 'looking': 102,\n",
       " 'sure': 103,\n",
       " 'guess': 104,\n",
       " 'ever': 105,\n",
       " 'made': 106,\n",
       " 'awesome': 107,\n",
       " 'guys': 108,\n",
       " 'help': 109,\n",
       " 'nothing': 110,\n",
       " 'year': 111,\n",
       " 'maybe': 112,\n",
       " 'look': 113,\n",
       " 'this': 114,\n",
       " 'thought': 115,\n",
       " 'summer': 116,\n",
       " 'poor': 117,\n",
       " 'things': 118,\n",
       " 'missing': 119,\n",
       " 'weather': 120,\n",
       " 'thank': 121,\n",
       " 'hurts': 122,\n",
       " 'cool': 123,\n",
       " 'have': 124,\n",
       " 'hard': 125,\n",
       " 'friend': 126,\n",
       " 'pretty': 127,\n",
       " 'tweet': 128,\n",
       " 'cold': 129,\n",
       " 'gone': 130,\n",
       " 'baby': 131,\n",
       " 'since': 132,\n",
       " 'live': 133,\n",
       " 'start': 134,\n",
       " 'looks': 135,\n",
       " 'late': 136,\n",
       " 'keep': 137,\n",
       " 'hear': 138,\n",
       " 'yesterday': 139,\n",
       " 'coming': 140,\n",
       " 'makes': 141,\n",
       " 'movie': 142,\n",
       " 'waiting': 143,\n",
       " 'head': 144,\n",
       " 'girl': 145,\n",
       " 'also': 146,\n",
       " 'finally': 147,\n",
       " 'said': 148,\n",
       " 'play': 149,\n",
       " 'stuff': 150,\n",
       " 'iphone': 151,\n",
       " 'leave': 152,\n",
       " 'actually': 153,\n",
       " 'woke': 154,\n",
       " 'might': 155,\n",
       " 'tell': 156,\n",
       " 'game': 157,\n",
       " 'wanted': 158,\n",
       " 'anything': 159,\n",
       " 'stupid': 160,\n",
       " 'many': 161,\n",
       " 'stop': 162,\n",
       " 'around': 163,\n",
       " 'thats': 164,\n",
       " 'anymore': 165,\n",
       " 'shit': 166,\n",
       " 'monday': 167,\n",
       " 'must': 168,\n",
       " 'found': 169,\n",
       " 'without': 170,\n",
       " 'later': 171,\n",
       " 'friday': 172,\n",
       " 'hour': 173,\n",
       " 'talk': 174,\n",
       " 'till': 175,\n",
       " 'call': 176,\n",
       " 'party': 177,\n",
       " 'sunday': 178,\n",
       " 'didnt': 179,\n",
       " 'follow': 180,\n",
       " 'amazing': 181,\n",
       " 'believe': 182,\n",
       " 'headache': 183,\n",
       " 'least': 184,\n",
       " 'give': 185,\n",
       " 'wrong': 186,\n",
       " 'making': 187,\n",
       " 'read': 188,\n",
       " 'world': 189,\n",
       " 'almost': 190,\n",
       " 'mean': 191,\n",
       " 'cause': 192,\n",
       " 'anyone': 193,\n",
       " 'everything': 194,\n",
       " 'hair': 195,\n",
       " 'food': 196,\n",
       " 'they': 197,\n",
       " 'times': 198,\n",
       " 'outside': 199,\n",
       " 'birthday': 200,\n",
       " 'music': 201,\n",
       " 'song': 202,\n",
       " 'glad': 203,\n",
       " 'weeks': 204,\n",
       " 'luck': 205,\n",
       " 'enough': 206,\n",
       " 'wants': 207,\n",
       " 'family': 208,\n",
       " 'mine': 209,\n",
       " 'okay': 210,\n",
       " 'thinking': 211,\n",
       " 'money': 212,\n",
       " 'lunch': 213,\n",
       " 'hurt': 214,\n",
       " 'every': 215,\n",
       " 'sounds': 216,\n",
       " 'room': 217,\n",
       " 'probably': 218,\n",
       " 'totally': 219,\n",
       " 'real': 220,\n",
       " 'stay': 221,\n",
       " 'tinyurl': 222,\n",
       " 'exam': 223,\n",
       " 'finished': 224,\n",
       " 'excited': 225,\n",
       " 'forgot': 226,\n",
       " 'stuck': 227,\n",
       " 'class': 228,\n",
       " 'sooo': 229,\n",
       " 'raining': 230,\n",
       " 'able': 231,\n",
       " 'free': 232,\n",
       " 'playing': 233,\n",
       " 'leaving': 234,\n",
       " 'check': 235,\n",
       " 'forward': 236,\n",
       " 'plurk': 237,\n",
       " 'alone': 238,\n",
       " 'kinda': 239,\n",
       " 'whole': 240,\n",
       " 'busy': 241,\n",
       " 'news': 242,\n",
       " 'tried': 243,\n",
       " 'beautiful': 244,\n",
       " 'dinner': 245,\n",
       " 'half': 246,\n",
       " 'coffee': 247,\n",
       " 'video': 248,\n",
       " 'computer': 249,\n",
       " 'wont': 250,\n",
       " 'either': 251,\n",
       " 'pain': 252,\n",
       " 'says': 253,\n",
       " 'saturday': 254,\n",
       " 'took': 255,\n",
       " 'awww': 256,\n",
       " 'place': 257,\n",
       " 'fuck': 258,\n",
       " 'came': 259,\n",
       " 'feels': 260,\n",
       " 'hell': 261,\n",
       " 'tweets': 262,\n",
       " 'seen': 263,\n",
       " 'broke': 264,\n",
       " 'taking': 265,\n",
       " 'internet': 266,\n",
       " 'face': 267,\n",
       " 'office': 268,\n",
       " 'seems': 269,\n",
       " 'kids': 270,\n",
       " 'super': 271,\n",
       " 'listening': 272,\n",
       " 'crazy': 273,\n",
       " 'funny': 274,\n",
       " 'else': 275,\n",
       " 'boring': 276,\n",
       " 'years': 277,\n",
       " 'needs': 278,\n",
       " 'used': 279,\n",
       " 'sitting': 280,\n",
       " 'idea': 281,\n",
       " 'crap': 282,\n",
       " 'eating': 283,\n",
       " 'awake': 284,\n",
       " 'hopefully': 285,\n",
       " 'followers': 286,\n",
       " 'enjoy': 287,\n",
       " 'heart': 288,\n",
       " 'died': 289,\n",
       " 'cute': 290,\n",
       " 'sore': 291,\n",
       " 'full': 292,\n",
       " 'hungry': 293,\n",
       " 'beach': 294,\n",
       " 'sweet': 295,\n",
       " 'asleep': 296,\n",
       " 'there': 297,\n",
       " 'rest': 298,\n",
       " 'following': 299,\n",
       " 'hahaha': 300,\n",
       " 'post': 301,\n",
       " 'fail': 302,\n",
       " 'mother': 303,\n",
       " 'heard': 304,\n",
       " 'wake': 305,\n",
       " 'started': 306,\n",
       " 'study': 307,\n",
       " 'break': 308,\n",
       " 'seriously': 309,\n",
       " 'true': 310,\n",
       " 'sigh': 311,\n",
       " 'book': 312,\n",
       " 'online': 313,\n",
       " 'lots': 314,\n",
       " 'homework': 315,\n",
       " 'happened': 316,\n",
       " 'dead': 317,\n",
       " 'suck': 318,\n",
       " 'told': 319,\n",
       " 'trip': 320,\n",
       " 'goes': 321,\n",
       " 'jealous': 322,\n",
       " 'name': 323,\n",
       " 'send': 324,\n",
       " 'watched': 325,\n",
       " 'remember': 326,\n",
       " 'lovely': 327,\n",
       " 'change': 328,\n",
       " 'starting': 329,\n",
       " 'update': 330,\n",
       " 'part': 331,\n",
       " 'facebook': 332,\n",
       " 'meet': 333,\n",
       " 'minutes': 334,\n",
       " 'sleeping': 335,\n",
       " 'reading': 336,\n",
       " 'mind': 337,\n",
       " 'talking': 338,\n",
       " 'shopping': 339,\n",
       " 'gets': 340,\n",
       " 'season': 341,\n",
       " 'instead': 342,\n",
       " 'open': 343,\n",
       " 'will': 344,\n",
       " 'girls': 345,\n",
       " 'drive': 346,\n",
       " 'called': 347,\n",
       " 'seeing': 348,\n",
       " 'exams': 349,\n",
       " 'nite': 350,\n",
       " 'fucking': 351,\n",
       " 'welcome': 352,\n",
       " 'kind': 353,\n",
       " 'unfortunately': 354,\n",
       " 'broken': 355,\n",
       " 'month': 356,\n",
       " 'throat': 357,\n",
       " 'lucky': 358,\n",
       " 'laptop': 359,\n",
       " 'worst': 360,\n",
       " 'concert': 361,\n",
       " 'picture': 362,\n",
       " 'person': 363,\n",
       " 'reply': 364,\n",
       " 'dude': 365,\n",
       " 'quite': 366,\n",
       " 'blog': 367,\n",
       " 'hoping': 368,\n",
       " 'soooo': 369,\n",
       " 'move': 370,\n",
       " 'care': 371,\n",
       " 'walk': 372,\n",
       " 'studying': 373,\n",
       " 'sunny': 374,\n",
       " 'goodnight': 375,\n",
       " 'sister': 376,\n",
       " 'breakfast': 377,\n",
       " 'link': 378,\n",
       " 'horrible': 379,\n",
       " 'finish': 380,\n",
       " 'wishing': 381,\n",
       " 'anyway': 382,\n",
       " 'ipod': 383,\n",
       " 'hello': 384,\n",
       " 'text': 385,\n",
       " 'running': 386,\n",
       " 'months': 387,\n",
       " 'eyes': 388,\n",
       " 'seem': 389,\n",
       " 'pics': 390,\n",
       " 'site': 391,\n",
       " 'sometimes': 392,\n",
       " 'bring': 393,\n",
       " 'course': 394,\n",
       " 'supposed': 395,\n",
       " 'upset': 396,\n",
       " 'problem': 397,\n",
       " 'happen': 398,\n",
       " 'bout': 399,\n",
       " 'fine': 400,\n",
       " 'means': 401,\n",
       " 'test': 402,\n",
       " 'bought': 403,\n",
       " 'fall': 404,\n",
       " 'lmao': 405,\n",
       " 'brother': 406,\n",
       " 'high': 407,\n",
       " 'loved': 408,\n",
       " 'heading': 409,\n",
       " 'where': 410,\n",
       " 'reason': 411,\n",
       " 'dear': 412,\n",
       " 'goin': 413,\n",
       " 'town': 414,\n",
       " 'worse': 415,\n",
       " 'afternoon': 416,\n",
       " 'youtube': 417,\n",
       " 'dream': 418,\n",
       " 'water': 419,\n",
       " 'less': 420,\n",
       " 'write': 421,\n",
       " 'shower': 422,\n",
       " 'close': 423,\n",
       " 'tickets': 424,\n",
       " 'city': 425,\n",
       " 'scared': 426,\n",
       " 'sleepy': 427,\n",
       " 'june': 428,\n",
       " 'doesnt': 429,\n",
       " 'final': 430,\n",
       " 'fell': 431,\n",
       " 'weird': 432,\n",
       " 'mood': 433,\n",
       " 'very': 434,\n",
       " 'fast': 435,\n",
       " 'tour': 436,\n",
       " 'sadly': 437,\n",
       " 'stomach': 438,\n",
       " 'drink': 439,\n",
       " 'english': 440,\n",
       " 'hehe': 441,\n",
       " 'ones': 442,\n",
       " 'clean': 443,\n",
       " 'couple': 444,\n",
       " 'side': 445,\n",
       " 'email': 446,\n",
       " 'store': 447,\n",
       " 'comes': 448,\n",
       " 'past': 449,\n",
       " 'slow': 450,\n",
       " 'together': 451,\n",
       " 'shame': 452,\n",
       " 'turn': 453,\n",
       " 'sound': 454,\n",
       " 'tommcfly': 455,\n",
       " 'longer': 456,\n",
       " 'works': 457,\n",
       " 'moving': 458,\n",
       " 'apparently': 459,\n",
       " 'mileycyrus': 460,\n",
       " 'church': 461,\n",
       " 'meeting': 462,\n",
       " 'when': 463,\n",
       " 'only': 464,\n",
       " 'short': 465,\n",
       " 'your': 466,\n",
       " 'crying': 467,\n",
       " 'college': 468,\n",
       " 'definitely': 469,\n",
       " 'tummy': 470,\n",
       " 'boys': 471,\n",
       " 'moment': 472,\n",
       " 'three': 473,\n",
       " 'saying': 474,\n",
       " 'understand': 475,\n",
       " 'driving': 476,\n",
       " 'london': 477,\n",
       " 'cleaning': 478,\n",
       " 'knew': 479,\n",
       " 'favorite': 480,\n",
       " 'second': 481,\n",
       " 'flight': 482,\n",
       " 'movies': 483,\n",
       " 'using': 484,\n",
       " 'fair': 485,\n",
       " 'ddlovato': 486,\n",
       " 'ride': 487,\n",
       " 'lonely': 488,\n",
       " 'hang': 489,\n",
       " 'holiday': 490,\n",
       " 'catch': 491,\n",
       " 'listen': 492,\n",
       " 'cream': 493,\n",
       " 'page': 494,\n",
       " 'visit': 495,\n",
       " 'body': 496,\n",
       " 'nope': 497,\n",
       " 'star': 498,\n",
       " 'hand': 499,\n",
       " 'evening': 500,\n",
       " 'list': 501,\n",
       " 'writing': 502,\n",
       " 'hospital': 503,\n",
       " 'parents': 504,\n",
       " 'chance': 505,\n",
       " 'rather': 506,\n",
       " 'ouch': 507,\n",
       " 'dance': 508,\n",
       " 'rock': 509,\n",
       " 'gave': 510,\n",
       " 'train': 511,\n",
       " 'hates': 512,\n",
       " 'slept': 513,\n",
       " 'mothers': 514,\n",
       " 'wonder': 515,\n",
       " 'black': 516,\n",
       " 'whats': 517,\n",
       " 'havent': 518,\n",
       " 'david': 519,\n",
       " 'spent': 520,\n",
       " 'then': 521,\n",
       " 'chocolate': 522,\n",
       " 'account': 523,\n",
       " 'rainy': 524,\n",
       " 'earlier': 525,\n",
       " 'forever': 526,\n",
       " 'story': 527,\n",
       " 'plans': 528,\n",
       " 'sent': 529,\n",
       " 'enjoying': 530,\n",
       " 'wondering': 531,\n",
       " 'airport': 532,\n",
       " 'hugs': 533,\n",
       " 'inside': 534,\n",
       " 'songs': 535,\n",
       " 'plus': 536,\n",
       " 'vacation': 537,\n",
       " 'wonderful': 538,\n",
       " 'except': 539,\n",
       " 'shows': 540,\n",
       " 'huge': 541,\n",
       " 'agree': 542,\n",
       " 'myspace': 543,\n",
       " 'goodbye': 544,\n",
       " 'tuesday': 545,\n",
       " 'worth': 546,\n",
       " 'pick': 547,\n",
       " 'spend': 548,\n",
       " 'bummed': 549,\n",
       " 'point': 550,\n",
       " 'kill': 551,\n",
       " 'lame': 552,\n",
       " 'camera': 553,\n",
       " 'updates': 554,\n",
       " 'lady': 555,\n",
       " 'killing': 556,\n",
       " 'forget': 557,\n",
       " 'terrible': 558,\n",
       " 'ahhh': 559,\n",
       " 'thursday': 560,\n",
       " 'word': 561,\n",
       " 'photo': 562,\n",
       " 'keeps': 563,\n",
       " 'sold': 564,\n",
       " 'perfect': 565,\n",
       " 'green': 566,\n",
       " 'paper': 567,\n",
       " 'isnt': 568,\n",
       " 'pictures': 569,\n",
       " 'drinking': 570,\n",
       " 'interesting': 571,\n",
       " 'team': 572,\n",
       " 'wear': 573,\n",
       " 'loves': 574,\n",
       " 'voice': 575,\n",
       " 'figure': 576,\n",
       " 'mins': 577,\n",
       " 'pool': 578,\n",
       " 'plan': 579,\n",
       " 'line': 580,\n",
       " 'felt': 581,\n",
       " 'tweeting': 582,\n",
       " 'album': 583,\n",
       " 'date': 584,\n",
       " 'sunshine': 585,\n",
       " 'lazy': 586,\n",
       " 'park': 587,\n",
       " 'apple': 588,\n",
       " 'wedding': 589,\n",
       " 'disappointed': 590,\n",
       " 'dreams': 591,\n",
       " 'answer': 592,\n",
       " 'thinks': 593,\n",
       " 'especially': 594,\n",
       " 'wishes': 595,\n",
       " 'boyfriend': 596,\n",
       " 'message': 597,\n",
       " 'feet': 598,\n",
       " 'power': 599,\n",
       " 'easy': 600,\n",
       " 'save': 601,\n",
       " 'looked': 602,\n",
       " 'scary': 603,\n",
       " 'episode': 604,\n",
       " 'realized': 605,\n",
       " 'blip': 606,\n",
       " 'awful': 607,\n",
       " 'white': 608,\n",
       " 'taken': 609,\n",
       " 'card': 610,\n",
       " 'dying': 611,\n",
       " 'finals': 612,\n",
       " 'does': 613,\n",
       " 'annoying': 614,\n",
       " 'jonas': 615,\n",
       " 'lose': 616,\n",
       " 'warm': 617,\n",
       " 'worried': 618,\n",
       " 'learn': 619,\n",
       " 'revision': 620,\n",
       " 'website': 621,\n",
       " 'bday': 622,\n",
       " 'bike': 623,\n",
       " 'shop': 624,\n",
       " 'packing': 625,\n",
       " 'small': 626,\n",
       " 'pissed': 627,\n",
       " 'with': 628,\n",
       " 'number': 629,\n",
       " 'waking': 630,\n",
       " 'download': 631,\n",
       " 'again': 632,\n",
       " 'officially': 633,\n",
       " 'meant': 634,\n",
       " 'been': 635,\n",
       " 'hubby': 636,\n",
       " 'july': 637,\n",
       " 'loving': 638,\n",
       " 'chat': 639,\n",
       " 'fever': 640,\n",
       " 'special': 641,\n",
       " 'band': 642,\n",
       " 'radio': 643,\n",
       " 'different': 644,\n",
       " 'near': 645,\n",
       " 'worked': 646,\n",
       " 'games': 647,\n",
       " 'sims': 648,\n",
       " 'closed': 649,\n",
       " 'turned': 650,\n",
       " 'words': 651,\n",
       " 'behind': 652,\n",
       " 'project': 653,\n",
       " 'some': 654,\n",
       " 'bloody': 655,\n",
       " 'nobody': 656,\n",
       " 'bummer': 657,\n",
       " 'road': 658,\n",
       " 'nose': 659,\n",
       " 'decided': 660,\n",
       " 'blue': 661,\n",
       " 'happens': 662,\n",
       " 'service': 663,\n",
       " 'starts': 664,\n",
       " 'tweetdeck': 665,\n",
       " 'sign': 666,\n",
       " 'photos': 667,\n",
       " 'shoes': 668,\n",
       " 'cake': 669,\n",
       " 'fact': 670,\n",
       " 'death': 671,\n",
       " 'front': 672,\n",
       " 'living': 673,\n",
       " 'argh': 674,\n",
       " 'support': 675,\n",
       " 'passed': 676,\n",
       " 'traffic': 677,\n",
       " 'google': 678,\n",
       " 'congrats': 679,\n",
       " 'having': 680,\n",
       " 'plane': 681,\n",
       " 'dang': 682,\n",
       " 'pizza': 683,\n",
       " 'although': 684,\n",
       " 'beer': 685,\n",
       " 'played': 686,\n",
       " 'upload': 687,\n",
       " 'aint': 688,\n",
       " 'more': 689,\n",
       " 'fans': 690,\n",
       " 'kate': 691,\n",
       " 'case': 692,\n",
       " 'beat': 693,\n",
       " 'lately': 694,\n",
       " 'liked': 695,\n",
       " 'french': 696,\n",
       " 'club': 697,\n",
       " 'blah': 698,\n",
       " 'hmmm': 699,\n",
       " 'gosh': 700,\n",
       " 'miley': 701,\n",
       " 'math': 702,\n",
       " 'wednesday': 703,\n",
       " 'books': 704,\n",
       " 'none': 705,\n",
       " 'join': 706,\n",
       " 'gutted': 707,\n",
       " 'gettin': 708,\n",
       " 'shirt': 709,\n",
       " 'freaking': 710,\n",
       " 'drunk': 711,\n",
       " 'walking': 712,\n",
       " 'completely': 713,\n",
       " 'failed': 714,\n",
       " 'chicken': 715,\n",
       " 'pass': 716,\n",
       " 'giving': 717,\n",
       " 'exhausted': 718,\n",
       " 'dress': 719,\n",
       " 'babe': 720,\n",
       " 'absolutely': 721,\n",
       " 'clothes': 722,\n",
       " 'cancelled': 723,\n",
       " 'minute': 724,\n",
       " 'worry': 725,\n",
       " 'needed': 726,\n",
       " 'vegas': 727,\n",
       " 'problems': 728,\n",
       " 'bitch': 729,\n",
       " 'ache': 730,\n",
       " 'mommy': 731,\n",
       " 'history': 732,\n",
       " 'maths': 733,\n",
       " 'depressed': 734,\n",
       " 'badly': 735,\n",
       " 'serious': 736,\n",
       " 'order': 737,\n",
       " 'hanging': 738,\n",
       " 'staying': 739,\n",
       " 'graduation': 740,\n",
       " 'stopped': 741,\n",
       " 'here': 742,\n",
       " 'touch': 743,\n",
       " 'exactly': 744,\n",
       " 'doctor': 745,\n",
       " 'business': 746,\n",
       " 'dark': 747,\n",
       " 'nights': 748,\n",
       " 'about': 749,\n",
       " 'alright': 750,\n",
       " 'safe': 751,\n",
       " 'followfriday': 752,\n",
       " 'lets': 753,\n",
       " 'dunno': 754,\n",
       " 'self': 755,\n",
       " 'alot': 756,\n",
       " 'door': 757,\n",
       " 'knows': 758,\n",
       " 'pink': 759,\n",
       " 'smile': 760,\n",
       " 'ended': 761,\n",
       " 'father': 762,\n",
       " 'mail': 763,\n",
       " 'vote': 764,\n",
       " 'nick': 765,\n",
       " 'burnt': 766,\n",
       " 'couldnt': 767,\n",
       " 'confused': 768,\n",
       " 'single': 769,\n",
       " 'caught': 770,\n",
       " 'dropped': 771,\n",
       " 'heat': 772,\n",
       " 'ticket': 773,\n",
       " 'foot': 774,\n",
       " 'teeth': 775,\n",
       " 'profile': 776,\n",
       " 'awwww': 777,\n",
       " 'wife': 778,\n",
       " 'company': 779,\n",
       " 'trouble': 780,\n",
       " 'dentist': 781,\n",
       " 'itunes': 782,\n",
       " 'france': 783,\n",
       " 'nearly': 784,\n",
       " 'cook': 785,\n",
       " 'screen': 786,\n",
       " 'whatever': 787,\n",
       " 'myloc': 788,\n",
       " 'asked': 789,\n",
       " 'brothers': 790,\n",
       " 'light': 791,\n",
       " 'country': 792,\n",
       " 'fixed': 793,\n",
       " 'changed': 794,\n",
       " 'window': 795,\n",
       " 'hold': 796,\n",
       " 'garden': 797,\n",
       " 'theres': 798,\n",
       " 'sooooo': 799,\n",
       " 'puppy': 800,\n",
       " 'round': 801,\n",
       " 'everybody': 802,\n",
       " 'version': 803,\n",
       " 'blackberry': 804,\n",
       " 'shall': 805,\n",
       " 'depressing': 806,\n",
       " 'wine': 807,\n",
       " 'blood': 808,\n",
       " 'shoot': 809,\n",
       " 'xoxo': 810,\n",
       " 'ahead': 811,\n",
       " 'windows': 812,\n",
       " 'usually': 813,\n",
       " 'storm': 814,\n",
       " 'should': 815,\n",
       " 'camp': 816,\n",
       " 'guitar': 817,\n",
       " 'videos': 818,\n",
       " 'question': 819,\n",
       " 'daddy': 820,\n",
       " 'daughter': 821,\n",
       " 'pray': 822,\n",
       " 'losing': 823,\n",
       " 'somewhere': 824,\n",
       " 'film': 825,\n",
       " 'major': 826,\n",
       " 'misses': 827,\n",
       " 'bank': 828,\n",
       " 'deal': 829,\n",
       " 'hotel': 830,\n",
       " 'wasnt': 831,\n",
       " 'afford': 832,\n",
       " 'middle': 833,\n",
       " 'legs': 834,\n",
       " 'swine': 835,\n",
       " 'shut': 836,\n",
       " 'along': 837,\n",
       " 'chris': 838,\n",
       " 'headed': 839,\n",
       " 'awards': 840,\n",
       " 'killed': 841,\n",
       " 'cried': 842,\n",
       " 'extra': 843,\n",
       " 'dogs': 844,\n",
       " 'darn': 845,\n",
       " 'drop': 846,\n",
       " 'laugh': 847,\n",
       " 'quick': 848,\n",
       " 'takes': 849,\n",
       " 'after': 850,\n",
       " 'random': 851,\n",
       " 'afraid': 852,\n",
       " 'fingers': 853,\n",
       " 'crappy': 854,\n",
       " 'jonasbrothers': 855,\n",
       " 'spending': 856,\n",
       " 'shot': 857,\n",
       " 'exciting': 858,\n",
       " 'currently': 859,\n",
       " 'mobile': 860,\n",
       " 'wearing': 861,\n",
       " 'feelin': 862,\n",
       " 'expensive': 863,\n",
       " 'share': 864,\n",
       " 'posted': 865,\n",
       " 'note': 866,\n",
       " 'available': 867,\n",
       " 'classes': 868,\n",
       " 'hangover': 869,\n",
       " 'hands': 870,\n",
       " 'gorgeous': 871,\n",
       " 'cheese': 872,\n",
       " 'interview': 873,\n",
       " 'fight': 874,\n",
       " 'double': 875,\n",
       " 'neck': 876,\n",
       " 'fire': 877,\n",
       " 'falling': 878,\n",
       " 'matter': 879,\n",
       " 'yummy': 880,\n",
       " 'brain': 881,\n",
       " 'mouth': 882,\n",
       " 'mcfly': 883,\n",
       " 'training': 884,\n",
       " 'thru': 885,\n",
       " 'anywhere': 886,\n",
       " 'suppose': 887,\n",
       " 'sort': 888,\n",
       " 'normal': 889,\n",
       " 'peace': 890,\n",
       " 'calling': 891,\n",
       " 'pack': 892,\n",
       " 'husband': 893,\n",
       " 'comment': 894,\n",
       " 'practice': 895,\n",
       " 'silly': 896,\n",
       " 'laundry': 897,\n",
       " 'hahah': 898,\n",
       " 'hurting': 899,\n",
       " 'cousin': 900,\n",
       " 'battery': 901,\n",
       " 'trek': 902,\n",
       " 'nervous': 903,\n",
       " 'empty': 904,\n",
       " 'usual': 905,\n",
       " 'twilight': 906,\n",
       " 'load': 907,\n",
       " 'moon': 908,\n",
       " 'thoughts': 909,\n",
       " 'young': 910,\n",
       " 'group': 911,\n",
       " 'type': 912,\n",
       " 'happening': 913,\n",
       " 'singing': 914,\n",
       " 'kitty': 915,\n",
       " 'gotten': 916,\n",
       " 'somebody': 917,\n",
       " 'miles': 918,\n",
       " 'stand': 919,\n",
       " 'issues': 920,\n",
       " 'dammit': 921,\n",
       " 'paid': 922,\n",
       " 'possible': 923,\n",
       " 'allowed': 924,\n",
       " 'laying': 925,\n",
       " 'quiet': 926,\n",
       " 'others': 927,\n",
       " 'indeed': 928,\n",
       " 'straight': 929,\n",
       " 'four': 930,\n",
       " 'ages': 931,\n",
       " 'cell': 932,\n",
       " 'sing': 933,\n",
       " 'freakin': 934,\n",
       " 'tears': 935,\n",
       " 'series': 936,\n",
       " 'adam': 937,\n",
       " 'john': 938,\n",
       " 'milk': 939,\n",
       " 'cough': 940,\n",
       " 'starbucks': 941,\n",
       " 'watchin': 942,\n",
       " 'doubt': 943,\n",
       " 'fish': 944,\n",
       " 'street': 945,\n",
       " 'prob': 946,\n",
       " 'knee': 947,\n",
       " 'chicago': 948,\n",
       " 'mess': 949,\n",
       " 'info': 950,\n",
       " 'state': 951,\n",
       " 'australia': 952,\n",
       " 'prom': 953,\n",
       " 'shift': 954,\n",
       " 'shes': 955,\n",
       " 'moved': 956,\n",
       " 'however': 957,\n",
       " 'doin': 958,\n",
       " 'tumblr': 959,\n",
       " 'epic': 960,\n",
       " 'ball': 961,\n",
       " 'stayed': 962,\n",
       " 'record': 963,\n",
       " 'loads': 964,\n",
       " 'calls': 965,\n",
       " 'honey': 966,\n",
       " 'relaxing': 967,\n",
       " 'putting': 968,\n",
       " 'hills': 969,\n",
       " 'sale': 970,\n",
       " 'enjoyed': 971,\n",
       " 'annoyed': 972,\n",
       " 'woman': 973,\n",
       " 'wanting': 974,\n",
       " 'checked': 975,\n",
       " 'mall': 976,\n",
       " 'outta': 977,\n",
       " 'barely': 978,\n",
       " 'finger': 979,\n",
       " 'loss': 980,\n",
       " 'helping': 981,\n",
       " 'grrr': 982,\n",
       " 'often': 983,\n",
       " 'ruined': 984,\n",
       " 'magic': 985,\n",
       " 'taylor': 986,\n",
       " 'sell': 987,\n",
       " 'future': 988,\n",
       " 'showing': 989,\n",
       " 'view': 990,\n",
       " 'nooo': 991,\n",
       " 'finale': 992,\n",
       " 'floor': 993,\n",
       " 'mate': 994,\n",
       " 'surgery': 995,\n",
       " 'swimming': 996,\n",
       " 'moms': 997,\n",
       " 'search': 998,\n",
       " 'sending': 999,\n",
       " 'messages': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-19063fc23f18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2374\u001b[0m     \"\"\"\n\u001b[0;32m   2375\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2376\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2377\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2378\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "# Simple Neural Network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, ),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[0,0] = 855 is not in [0, 1)\n\t [[node sequential_6/embedding_6/embedding_lookup (defined at <ipython-input-71-123b63ea3ac3>:1) ]] [Op:__inference_train_function_5314]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_6/embedding_6/embedding_lookup:\n sequential_6/embedding_6/embedding_lookup/5046 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-123b63ea3ac3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[0,0] = 855 is not in [0, 1)\n\t [[node sequential_6/embedding_6/embedding_lookup (defined at <ipython-input-71-123b63ea3ac3>:1) ]] [Op:__inference_train_function_5314]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_6/embedding_6/embedding_lookup:\n sequential_6/embedding_6/embedding_lookup/5046 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_padded, y_train, batch_size = 256, epochs=10, verbose=2, validation_data=(X_test_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 100)         100       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 3,530\n",
      "Trainable params: 3,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 100),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(6, activation = 'softmax')\n",
    "])\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[120,0] = 11 is not in [0, 1)\n\t [[node sequential_4/embedding_4/embedding_lookup (defined at <ipython-input-64-123b63ea3ac3>:1) ]] [Op:__inference_train_function_3769]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_4/embedding_4/embedding_lookup:\n sequential_4/embedding_4/embedding_lookup/3524 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-123b63ea3ac3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[120,0] = 11 is not in [0, 1)\n\t [[node sequential_4/embedding_4/embedding_lookup (defined at <ipython-input-64-123b63ea3ac3>:1) ]] [Op:__inference_train_function_3769]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_4/embedding_4/embedding_lookup:\n sequential_4/embedding_4/embedding_lookup/3524 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_padded, y_train, batch_size = 256, epochs=10, verbose=2, validation_data=(X_test_padded, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
